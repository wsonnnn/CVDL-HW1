{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入依赖的库\n",
    "import keras\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "import csv\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.initializers import he_normal\n",
    "from keras.layers import Dense,Input,add,Activation,Lambda,concatenate\n",
    "from keras.layers import Conv2D,AveragePooling2D,GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras import optimizers,regularizers\n",
    "from keras.callbacks import LearningRateScheduler,TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#声明所需要的常量\n",
    "train_path=r\"C:/Users/sll82/Downloads/bird/bird/train/train/\"\n",
    "train_type_path=r\"C:/Users/sll82/Downloads/bird/bird/train.csv\"\n",
    "valid_path=r\"C:/Users/sll82/Downloads/bird/bird/valid/valid/\"\n",
    "valid_type_path=r\"C:/Users/sll82/Downloads/bird/bird/valid.csv\"\n",
    "test_num=24497\n",
    "valid_num=900\n",
    "img_rows=224\n",
    "img_cols=224\n",
    "img_channels=3\n",
    "classes=180\n",
    "batch_size=16\n",
    "weight_decay=1e-4\n",
    "compression=0.5\n",
    "growth_rate=12\n",
    "epochs=185\n",
    "iterations=400\n",
    "log_path=\"./densenet_save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#声明函数\n",
    "\n",
    "#加载图片\n",
    "def load_data(path,num):\n",
    "    data=[]\n",
    "    for i in range(num):\n",
    "        string=str(i).zfill(5)\n",
    "        img=cv2.imread(path+string+'.jpg')\n",
    "        data.append(img)\n",
    "    return data\n",
    "#加载类型数据\n",
    "def load_type(path):\n",
    "    y=[]\n",
    "    with open(path,\"r\",encoding=\"utf-8\") as f:\n",
    "        reader=csv.reader(f)\n",
    "        #print(type(reader))\n",
    "        i=0\n",
    "        for row in reader:\n",
    "            if i==0:\n",
    "                i+=1\n",
    "                continue\n",
    "            i+=1\n",
    "            #print(row[1])\n",
    "            y.append(int(row[1]))\n",
    "    return y\n",
    "#图片预处理\n",
    "def color_prefit(x):\n",
    "    x=x.astype('float32')\n",
    "    for i in range(3):\n",
    "        x[:,:,:,i]=(x[:,:,:,i]-np.mean(x[:,:,:,i]))/np.std(x[:,:,:,i])\n",
    "    return x\n",
    "#调整学习率\n",
    "def scheduler(epoch):\n",
    "    if epoch<60:\n",
    "        return 0.1\n",
    "    if epoch<110:\n",
    "        return 0.01\n",
    "    if epoch<150:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "#卷积层，使用正则化\n",
    "def conv(x,out_filters,k_size):\n",
    "    return Conv2D(filters=out_filters,\n",
    "                  kernel_size=k_size,\n",
    "                  strides=(1,1),\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=regularizers.l2(weight_decay),\n",
    "                  use_bias=False)(x)\n",
    "\n",
    "def BN_ReLU(x):\n",
    "    x = BatchNormalization(momentum=0.9, epsilon=1e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def bottleneck(x):\n",
    "    channels = growth_rate * 4\n",
    "    x = bn_relu(x)\n",
    "    x = conv(x, channels, (1,1))\n",
    "    x = bn_relu(x)\n",
    "    x = conv(x, growth_rate, (3,3))\n",
    "    return x\n",
    "\n",
    "def mid_trans(x, inputchannels):\n",
    "    outputchannels = int(inputchannels * compression)\n",
    "    x = BN_ReLU(x)\n",
    "    x = conv(x, outputchannels, (1,1))\n",
    "    x = AveragePooling2D((2,2), strides=(2, 2))(x)\n",
    "    return x, outputchannels\n",
    "\n",
    "def dense_block(x,blocks,nchannels):\n",
    "    concat = x\n",
    "    for i in range(blocks):\n",
    "        x = bottleneck(concat)\n",
    "        concat = concatenate([x,concat], axis=-1)\n",
    "        nchannels += growth_rate\n",
    "    return concat, nchannels\n",
    "\n",
    "def densenet(img_input,classes_num):\n",
    "    nchannels=growth_rate*2\n",
    "    x=conv(img_input,nchannels,(3,3))\n",
    "    x,nchannels=dense_block(x,8,nchannels)\n",
    "    x,nchannels=mid_trans(x,nchannels)\n",
    "    x,nchannels=dense_block(x,8,nchannels)\n",
    "    x,nchannels=mid_trans(x,nchannels)\n",
    "    x,nchannels=dense_block(x,8,nchannels)\n",
    "    x=BN_ReLU(x)\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(units=10,\n",
    "                 activation='softmax',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=regularizers.l2(weight_decay))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载存储数据\n",
    "train_x=np.array(load_data(train_path))\n",
    "np.save('bird_data.npy',train_x)\n",
    "\n",
    "train_y=np.array(load_type(train_type_path))\n",
    "np.save('bird_data_type.npy',train_y)\n",
    "\n",
    "valid_x=np.array(load_data(valid_path,valid_num))\n",
    "np.save('bird_valid.npy',valid_x)\n",
    "\n",
    "valid_y=np.array(load_type(valid_type_path))\n",
    "np.save('bird_valid_type.npy',valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入数据\n",
    "train_x=np.load('bird_data.npy')\n",
    "train_y=np.load('bird_data_type.npy')\n",
    "valid_x=np.load('bird_valid.npy')\n",
    "valid_y=np.load('bird_valid_type.npy')\n",
    "#类型->onehot向量\n",
    "y_train=keras.utils.to_categorical(train_y,classes)\n",
    "y_valid=keras.utils.to_categorical(valid_y,classes)\n",
    "#图片预处理\n",
    "x_train=color_prefit(train_x)\n",
    "x_valid=color_prefit(valid_x)\n",
    "#声明模型\n",
    "img_input=Input(shape=(img_rows,img_cols,img_channels))\n",
    "output=densenet(img_input,classes)\n",
    "model=Model(img_input,output)\n",
    "#print(model.summary())\n",
    "\n",
    "#优化器使用sgd\n",
    "sgd=optimizers.SGD(lr=.1,momentum=0.9,nesterov=True)\n",
    "\n",
    "#损失函数使用categorical_crossentropy，此外还试用了KL散度\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "#使用tensorboard进行数据可视化\n",
    "tb_cb=TensorBoard(log_dir=log_path,histogram_freq=0)\n",
    "change_lr=LearningRateScheduler(scheduler)\n",
    "cbks=[change_lr,tb_cb]\n",
    "\n",
    "#对预处理后的图像进行数据增强\n",
    "datapowerful=ImageDataGenerator(horizontal_flip=True,\n",
    "                          width_shift_range=0.125,\n",
    "                           vertical_flip=True,\n",
    "                          height_shift_range=0.125,\n",
    "                          fill_mode='constant',\n",
    "                          cval=0.)\n",
    "datagenpowerful.fit(x_train)\n",
    "\n",
    "#两种训练模型的方式，1 直接将全部图片加载到内存中，2 随用随取\n",
    "model.fit_generator(datapowerful.flow(x_train,_train,batch_size=batch_size),\n",
    "                   steps_per_epoch=iterations,\n",
    "                   epochs=epochs,\n",
    "                   callbacks=cbks,\n",
    "                   validation_data=(x_valid,y_valid))\n",
    "\n",
    "#这种方式需要将数据增强的方式在flow_from_directory中声明\n",
    "model.fit_generator(datapowerful.flow_from_directory(direction=\"./bird\",\n",
    "                    target_size=(224,224),class_mode='categorical',\n",
    "                    batch_size=batch_size,featurewise_std_normalization=True,\n",
    "                    rotation_range=0.1,width_shift_range=0.1,\n",
    "                    height_shift_range=0.1),\n",
    "                   steps_per_epoch=iterations,\n",
    "                   epochs=epochs,\n",
    "                   callbacks=cbks,\n",
    "                   validation_data=(x_valid,y_valid))\n",
    "\n",
    "model.save('densenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取训练好的模型，并对test数据进行预测\n",
    "path=\"C:/Users/sll82/Downloads/densenet(2).h5\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import load_model\n",
    "model=load_model(path)\n",
    "path2=\"C:/Users/sll82/Downloads/bird/bird/test/test/\"\n",
    "head=[\"ID\",\"Category\"]\n",
    "rows=[]\n",
    "for i in range(900):\n",
    "    img=cv2.imread(path2+str(i).zfill(5)+\".jpg\")\n",
    "    img=img.reshape(1,224,224,3).astype('float32')\n",
    "    for u in range(3):\n",
    "        img[:,:,:,u]=(img[:,:,:,u]-np.mean(img[:,:,:,u]))/np.std(img[:,:,:,u])\n",
    "    predict = model.predict(img)\n",
    "    predict=np.argmax(predict,axis=1)[0]\n",
    "    res={}\n",
    "    res['ID']=str(i).zfill(5)\n",
    "    res['Category']=predict\n",
    "    print(res)\n",
    "    rows.append(res)\n",
    "\n",
    "with open('res'+'sec'+'.csv','w',newline='',encoding='utf-8')as f2:\n",
    "    f_csv = csv.DictWriter(f2,head)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
